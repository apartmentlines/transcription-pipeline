x-python-image: &default_python_image python:3.12.9-slim-bookworm
# x-networks: &default_networks
#   - transcription-pipeline-network

x-build: &default_build
  context: .
  dockerfile: Dockerfile
  args:
    BASE_IMAGE: *default_python_image

x-environment: &environment
#   HF_HOME: /var/local/data/cache/huggingface
#   TORCH_HOME: /var/local/data/cache/torch
    NVIDIA_VISIBLE_DEVICES: all
    NVIDIA_DRIVER_CAPABILITIES: compute,utility

x-secrets-environment: &secrets_environment
  # HUGGINGFACEHUB_API_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}
  TRANSCRIPTION_API_KEY: ${TRANSCRIPTION_API_KEY}
  TRANSCRIPTION_DOMAIN: ${TRANSCRIPTION_DOMAIN}

x-command: &default_command [ "transcription-processor", "--limit", "1000", "--processing-limit", "2" ]
x-testing-command: &testing_command [ "sleep", "1d" ]

services:
  transcription-processor:
    build:
      <<: *default_build
    environment:
      <<:
        - *environment
        - *secrets_environment
    command: *default_command
    # command: *testing_command
    # networks: *default_networks
    # volumes:
    #   - transcription-processor-data:/var/local/data
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

# networks:
#   transcription-pipeline-network:
#
# volumes:
#   transcription-processor-data:
#     driver: local
